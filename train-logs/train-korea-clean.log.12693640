Device: cuda
Data directory: ./data
Seed: 20244078
Data name: korea-clean
./data/korea-clean-train.csv
./data/korea-clean-shuffled-train.csv
./data/korea-nocat-clean.csv
./data/korea-nocat-clean-shuffled-test.csv
./data/korea-nocat-clean-shuffled-train.csv
./data/corr-korea-clean-shuffled.png
./data/korea-clean.csv
./data/korea-clean-shuffled.csv
./data/korea-nocat-clean-shuffled.csv
./data/korea-nocat-clean-test.csv
./data/corr-korea-nocat-clean-shuffled.png
./data/korea-clean-test.csv
./data/korea-clean-shuffled-test.csv
./data/korea-nocat-clean-train.csv
Number of columns with NaN: 0
Correlation matrix save path: ./data/corr-korea-clean.png

A1                  0.606700
A2_1                0.536888
A2_2                0.514075
A2_3                0.457574
A3_1                0.510473
                      ...   
SQ1_7_7.0           0.009620
SQ1_8               0.109602
SQ1_9              -0.019753
year               -0.045233
happiness_ladder    1.000000
Name: happiness_ladder, Length: 299, dtype: float64

==========

Batch size: 32
Number of input features: 298
Lucky number: 42
Epochs: 200
Adam betas: 0.9, 0.999
Criterion: MSE loss


Training for korea-clean dataset with features=[298, 42, 84, 168, 336, 672, 336, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.83	Test SSE:   31.09
Epoch: 40	Train Loss:  0.79	Test SSE:   30.69
Epoch: 60	Train Loss:  0.77	Test SSE:   30.62
Epoch: 80	Train Loss:  0.75	Test SSE:   32.14
Epoch: 100	Train Loss:  0.73	Test SSE:   31.47
Epoch: 120	Train Loss:  0.71	Test SSE:   33.11
Epoch: 140	Train Loss:  0.70	Test SSE:   34.69
Epoch: 160	Train Loss:  0.69	Test SSE:   33.35
Epoch: 180	Train Loss:  0.68	Test SSE:   38.31
Epoch: 200	Train Loss:  0.68	Test SSE:   33.80

Training for korea-clean dataset with features=[298, 42, 84, 168, 336, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.82	Test SSE:   30.66
Epoch: 40	Train Loss:  0.77	Test SSE:   30.32
Epoch: 60	Train Loss:  0.74	Test SSE:   31.73
Epoch: 80	Train Loss:  0.71	Test SSE:   32.79
Epoch: 100	Train Loss:  0.69	Test SSE:   30.88
Epoch: 120	Train Loss:  0.67	Test SSE:   32.41
Epoch: 140	Train Loss:  0.65	Test SSE:   33.08
Epoch: 160	Train Loss:  0.64	Test SSE:   36.08
Epoch: 180	Train Loss:  0.62	Test SSE:   32.53
Epoch: 200	Train Loss:  0.61	Test SSE:   33.68

Training for korea-clean dataset with features=[298, 42, 84, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.81	Test SSE:   31.00
Epoch: 40	Train Loss:  0.77	Test SSE:   30.29
Epoch: 60	Train Loss:  0.75	Test SSE:   32.82
Epoch: 80	Train Loss:  0.73	Test SSE:   32.49
Epoch: 100	Train Loss:  0.72	Test SSE:   31.63
Epoch: 120	Train Loss:  0.70	Test SSE:   32.80
Epoch: 140	Train Loss:  0.69	Test SSE:   31.63
Epoch: 160	Train Loss:  0.68	Test SSE:   32.73
Epoch: 180	Train Loss:  0.68	Test SSE:   32.52
Epoch: 200	Train Loss:  0.67	Test SSE:   32.10

Training for korea-clean dataset with features=[298, 42, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.81	Test SSE:   34.68
Epoch: 40	Train Loss:  0.76	Test SSE:   33.79
Epoch: 60	Train Loss:  0.75	Test SSE:   32.29
Epoch: 80	Train Loss:  0.73	Test SSE:   31.97
Epoch: 100	Train Loss:  0.72	Test SSE:   30.51
Epoch: 120	Train Loss:  0.72	Test SSE:   32.20
Epoch: 140	Train Loss:  0.71	Test SSE:   32.23
Epoch: 160	Train Loss:  0.71	Test SSE:   31.93
Epoch: 180	Train Loss:  0.70	Test SSE:   33.40
Epoch: 200	Train Loss:  0.70	Test SSE:   32.92

Training for korea-clean dataset with features=[298, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.81	Test SSE:   31.12
Epoch: 40	Train Loss:  0.79	Test SSE:   30.96
Epoch: 60	Train Loss:  0.77	Test SSE:   31.89
Epoch: 80	Train Loss:  0.77	Test SSE:   30.62
Epoch: 100	Train Loss:  0.76	Test SSE:   31.35
Epoch: 120	Train Loss:  0.76	Test SSE:   31.53
Epoch: 140	Train Loss:  0.75	Test SSE:   30.95
Epoch: 160	Train Loss:  0.75	Test SSE:   32.87
Epoch: 180	Train Loss:  0.75	Test SSE:   34.31
Epoch: 200	Train Loss:  0.75	Test SSE:   31.33

SSE on testing dataset for korea-clean with 10 layers:	33.8034
SSE on testing dataset for korea-clean with 8 layers:	33.6775
SSE on testing dataset for korea-clean with 6 layers:	32.0969
SSE on testing dataset for korea-clean with 4 layers:	32.9194
SSE on testing dataset for korea-clean with 2 layers:	31.3275
                                  
================================= 
Global information about the job: 
================================= 
  
Job owner: brywi(43322)
Job name:  bryan
Node list: ravg1126
Job start: Sun Sep  8 17:34:36 CEST 2024
Job end:   Sun Sep  8 18:37:14 CEST 2024
Work dir:  /raven/u/brywi/korea-happiness
Command:   /raven/u/brywi/korea-happiness/train.sh
  
  
  
==========================================================================================
Information on jobsteps (Note: MaxRSS/AveRSS is the maximum/average over all 
tasks of the per-task memory high-water marks; cf. "man sacct"): 
==========================================================================================
  
JobID            JobName NNodes NTasks  NCPUS       MaxRSS       AveRSS    Elapsed ExitCode
------------- ---------- ------ ------ ------ ------------ ------------ ---------- --------
12693640           bryan      1            36                             01:02:38      0:0
  
Maximum memory per node: 5.879011 GB (defined as MaxRSS*Ntasks/NNodes)
CPU utilization: 6.2 %
  
